# AbstractAssistant ğŸ¤–

A sleek macOS system tray application providing instant access to Large Language Models with a modern Qt-based interface. Built with Python and powered by [AbstractCore](https://www.abstractcore.ai/).

## âœ¨ Features

- **ğŸ¯ System Tray Integration**: Quick access from macOS menu bar - always at your fingertips
- **ğŸ’¬ Modern Qt Interface**: Clean, iPhone Messages-style chat bubble with dark theme
- **ğŸ”Š Voice Support**: Text-to-Speech integration with VoiceLLM for conversational AI
- **ğŸ”„ Multi-Provider Support**: Seamlessly switch between LMStudio, OpenAI, Anthropic, Ollama, and more via AbstractCore
- **ğŸ“Š Real-time Status**: Live token counting, provider/model selection, and animated status indicators
- **ğŸ’¾ Session Management**: Save, load, and view conversation history with markdown rendering
- **âš™ï¸ Smart Controls**: Provider/model dropdowns, TTS toggle, and session buttons
- **ğŸ¨ Professional Design**: Rounded corners, smooth animations, and native macOS feel

## ğŸš€ Quick Start

### Installation

```bash
# Install from PyPI (recommended)
pip install abstractassistant

# Or install from source
git clone https://github.com/lpalbou/abstractassistant.git
cd abstractassistant
pip install -e .
```

### Launch

```bash
# Simple launch (no parameters needed!)
assistant

# With custom provider and model
assistant --provider lmstudio --model qwen/qwen3-next-80b

# With debug mode
assistant --debug

# With custom config
assistant --config my-config.toml

# Show help
assistant --help
```

### First Run

1. **Launch**: Run `assistant` in your terminal
2. **Look for the Icon**: Check your macOS menu bar (top-right) for the AbstractAssistant icon
3. **Click to Chat**: Click the icon to open the modern Qt chat bubble
4. **Start Conversing**: Type your message and press Shift+Enter or click the send button

## ğŸ® Usage

### Chat Interface

The main interface is a sleek Qt-based chat bubble that appears when you click the system tray icon:

- **Provider Selection**: Choose from LMStudio, OpenAI, Anthropic, Ollama, and more
- **Model Selection**: Pick your preferred model (automatically populated based on provider)
- **Text Input**: Type your message in the input area
- **Send**: Press Shift+Enter or click the blue send button (â†’)
- **Voice Mode**: Toggle the TTS switch for spoken responses
- **Session Controls**: Clear, Load, Save, and view History

### Session Management

- **Clear**: Start a fresh conversation
- **Save**: Save current conversation to file
- **Load**: Load a previous conversation
- **History**: View all messages in iPhone Messages-style dialog

### Voice Features

- **TTS Toggle**: Click the speaker icon to enable/disable Text-to-Speech
- **Voice Mode**: When enabled, AI responses are spoken aloud using VoiceLLM
- **Smart Prompting**: In voice mode, the AI uses shorter, conversational responses

### System Tray

- **Single Click**: Open/close the chat bubble
- **Animated Icon**: Visual feedback showing AI status (ready/generating)
- **Always Available**: Minimal resource usage when idle

## âš™ï¸ Configuration

Create a `config.toml` file to customize settings:

```toml
[ui]
theme = "dark"
always_on_top = true

[llm]
default_provider = "lmstudio"
default_model = "qwen/qwen3-next-80b"
max_tokens = 128000
temperature = 0.7

[system_tray]
icon_size = 64
```

### API Keys Setup

Set your API keys as environment variables:

```bash
# For OpenAI
export OPENAI_API_KEY="your_openai_key_here"

# For Anthropic
export ANTHROPIC_API_KEY="your_anthropic_key_here"

# For local models (LMStudio, Ollama), no API key needed
```

## ğŸ—ï¸ Architecture

AbstractAssistant follows a clean, modular design:

- **System Tray**: Native macOS integration with `pystray`
- **Qt Interface**: Modern chat bubble using PyQt5/PySide2/PyQt6
- **LLM Manager**: Universal provider support via AbstractCore
- **Voice Integration**: Text-to-Speech with VoiceLLM
- **Session Management**: Persistent conversation history
- **Icon Generator**: Dynamic, animated system tray icons

See [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) for detailed technical documentation.

## ğŸ”§ Development

### Running from Source

```bash
# Clone the repository
git clone https://github.com/lpalbou/abstractassistant.git
cd abstractassistant

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install in development mode
pip install -e .

# Run with debug mode
assistant --debug
```

### Project Structure

```
abstractassistant/
â”œâ”€â”€ pyproject.toml          # Package configuration
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ config.toml            # Default configuration
â”œâ”€â”€ abstractassistant/     # Main package
â”‚   â”œâ”€â”€ cli.py            # CLI entry point
â”‚   â”œâ”€â”€ app.py            # Main application
â”‚   â”œâ”€â”€ config.py         # Configuration management
â”‚   â”œâ”€â”€ core/             # Business logic
â”‚   â”‚   â”œâ”€â”€ llm_manager.py    # LLM provider management
â”‚   â”‚   â””â”€â”€ tts_manager.py    # Voice/TTS integration
â”‚   â”œâ”€â”€ ui/               # User interface
â”‚   â”‚   â”œâ”€â”€ qt_bubble.py      # Main Qt chat interface
â”‚   â”‚   â”œâ”€â”€ toast_window.py   # Notification system
â”‚   â”‚   â””â”€â”€ bubble_window.py  # Alternative webview interface
â”‚   â””â”€â”€ utils/            # Utilities
â”‚       â”œâ”€â”€ icon_generator.py # Dynamic icon creation
â”‚       â””â”€â”€ markdown_renderer.py # Markdown processing
â”œâ”€â”€ web/                  # Web interface assets (alternative UI)
â”‚   â”œâ”€â”€ index.html        # Full web interface
â”‚   â”œâ”€â”€ bubble.html       # Bubble-specific interface
â”‚   â”œâ”€â”€ styles.css        # Web styling
â”‚   â””â”€â”€ app.js           # Web application logic
â””â”€â”€ docs/                 # Documentation
    â”œâ”€â”€ ARCHITECTURE.md   # Technical documentation
    â”œâ”€â”€ INSTALLATION.md   # Installation guide
    â””â”€â”€ USAGE.md         # Usage guide
```

## ğŸŒŸ Why AbstractAssistant?

- **ğŸ¯ Focused**: Designed specifically for quick AI interactions
- **ğŸ¨ Beautiful**: Modern Qt interface with native macOS feel
- **âš¡ Fast**: Instant access without opening heavy applications
- **ğŸ”„ Flexible**: Support for multiple AI providers in one interface
- **ğŸ›¡ï¸ Robust**: Built with error handling and graceful fallbacks
- **ğŸ“± Unobtrusive**: Lives quietly in your menu bar until needed
- **ğŸ”Š Conversational**: Optional voice mode for natural AI interactions

## ğŸ“‹ Requirements

- **macOS**: 10.14+ (Mojave or later)
- **Python**: 3.9+
- **Qt**: PyQt5, PySide2, or PyQt6 (automatically detected)
- **Dependencies**: Automatically installed via pip

## ğŸ¤ Contributing

Contributions welcome! Please read the architecture documentation and follow the established patterns:

- **Clean Code**: Follow PEP 8 and use type hints
- **Modular Design**: Keep components focused and reusable
- **Modern UI/UX**: Maintain the sleek, native feel
- **Error Handling**: Always include graceful fallbacks
- **Documentation**: Update docs for any new features

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ™ Acknowledgments

This project is built on top of excellent open-source libraries:

- **[AbstractCore](https://www.abstractcore.ai/)**: Universal LLM interface library - the foundation that makes multi-provider support seamless
- **[VoiceLLM](https://github.com/lpalbou/voicellm)**: High-quality Text-to-Speech integration
- **[PyQt5/PySide2/PyQt6](https://www.qt.io/)**: Cross-platform GUI framework for the modern interface
- **[pystray](https://github.com/moses-palmer/pystray)**: Cross-platform system tray support
- **[Pillow](https://python-pillow.org/)**: Image processing for dynamic icon generation

See [ACKNOWLEDGMENTS.md](ACKNOWLEDGMENTS.md) for complete attribution.

---

**Built with â¤ï¸ for macOS users who want AI at their fingertips**